<?xml version="1.0" encoding="UTF-8"?>
<settings>
	<!--
	  Interval (in milliseconds) to invoke a crawl thread.
	  There is an HTTP hit every <interval> millisecond.
	-->
	<interval>250</interval>

	<!--
	  Interval (in milliseconds) to invoke a monitor thread.
	  Monitor adds new entry in the monitor.log every <monitorInterval>
          milliseconds.
      Moreover, every 20 entries, it displays a report with the slowest URLs.
	-->
	<monitorInterval>10000</monitorInterval>

	<!-- HTTP connection timeout in milliseconds -->
	<connectionTimeout>30000</connectionTimeout>


	<!-- Headers to be used by the http client crawler -->
	<headers>
		<header name="User-Agent">Mozilla</header>
		<header name="Cache-Control">no-cache</header>
		<header name="Accept-Language">en-US</header>
	</headers>


	<!-- URLs to start crawling from. You can enter multiple URLs. -->
	<crawl-urls>
		<!--
		<url>http://www.msn.com/</url>
		-->
		<url>https://yahoo.com</url>
	</crawl-urls>


	<!--
	  URL patterns
	  For each new URL, each pattern will be applied, one by one.
	  As soon as a pattern matches, the permission defined in the tag will be applied
	  (true = allow, false = deny), and the analysis stops (the other patterns won't be
      analyzed).
	  If no pattern matches, the default permission defined in the <url-pattern> tag
	  will be applied.

	  Pattern are:
	  - regular expressions
	  - case insensitive
	  - not substrings, so no need to add '^' or '$'.
	-->
	<url-patterns default_permission="false">
		<!-- If URLs contains '/search' => DENIED -->
		<pattern permission="false">.*/search/.*</pattern>
		<!-- Otherwise if PDF file => DENIED (matches also "foo.pdf?v=1") -->
		<pattern permission="false">.*\.pdf.*</pattern>
		<!-- Otherwise, if domain is *.yahoo.com => ALLOWED -->
		<pattern permission="true">https://.*?yahoo\.com.*</pattern>
		<!-- Otherwise (for all other domains), default permission: DENIED -->
	</url-patterns>


	<!--
		Additional crawl options
	-->
	<options>
		<!-- 
			true / false. If true, all assets (img, css, js) will be also downloaded.
			This can be usefull for example to test status code (be sure it's 200) ot
			to check in the report that there is no mixed content (http loaded from
			a https page)
		 -->
		<option name="assets">false</option>
	</options>

</settings>
